{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สวัสดีครับ! ยินดีที่ได้รู้จักครับ ผมชื่อ Typhoon สร้างโดย SCB 10X เพื่อช่วยคุณด้วยความช่วยเหลือ, ความปลอดภัย และความซื่อสัตย์ ผมยินดีเป็นอย่างยิ่งที่จะช่วยเหลือคุณในทุกๆ เรื่องที่ผมสามารถทำได้ครับ\n",
      "\n",
      "คุณมีอะไรให้ผมช่วยวันนี้ครับ?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:5433\"\n",
    "MODEL_NAME = \"scb10x/typhoon2.1-gemma3-4b:latest\"\n",
    "\n",
    "def generate(prompt: str) -> str:\n",
    "    \"\"\"เรียก /api/generate เพื่อสร้างข้อความตอบกลับ\"\"\"\n",
    "    res = requests.post(\n",
    "        f\"{API_URL}/api/generate\",\n",
    "        json={\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"response\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(generate(\"สวัสดี\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f306588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ได้ทั้งหมด 6 chunks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_and_chunk(directory: str, chunk_size: int = 500):\n",
    "    \"\"\"อ่านไฟล์ .txt ในโฟลเดอร์ แล้วแบ่งเป็นชิ้นละ chunk_size คำ\"\"\"\n",
    "    chunks = []\n",
    "    for fname in os.listdir(directory):\n",
    "        if not fname.endswith(\".txt\"):\n",
    "            continue\n",
    "        text = open(os.path.join(directory, fname), encoding=\"utf-8\").read()\n",
    "        words = text.split()\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = \" \".join(words[i : i + chunk_size])\n",
    "            # เก็บ metadata เบื้องต้นด้วย\n",
    "            chunks.append({\n",
    "                \"content\": chunk,\n",
    "                \"source\": fname\n",
    "            })\n",
    "    return chunks\n",
    "\n",
    "# usage\n",
    "directory = r\"D:\\TTT_Trainee\\Project_1\\AI-Chatbot\\data\"\n",
    "list_of_chunks = load_and_chunk(directory)\n",
    "print(f\"ได้ทั้งหมด {len(list_of_chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "219f718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# โหลดโมเดล embedding (ฟรี ไม่ต้องใช้ OpenAI API)\n",
    "embed_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# แปลงเป็นเวกเตอร์ 768 มิติ\n",
    "texts = [c[\"content\"] for c in list_of_chunks]\n",
    "embeddings = embed_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "# เพิ่ม embedding ลงใน list_of_chunks\n",
    "for chunk, emb in zip(list_of_chunks, embeddings):\n",
    "    chunk[\"vector\"] = emb.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57eff3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mydb\", user=\"admin\", password=\"1234\",\n",
    "    host=\"localhost\", port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "# สร้างตารางถ้ายังไม่มี\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS documents (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        content TEXT,\n",
    "        source TEXT,\n",
    "        embedding VECTOR(768)\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# แทรกข้อมูล\n",
    "for c in list_of_chunks:\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO documents (content, source, embedding)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", (c[\"content\"], c[\"source\"], c[\"vector\"]))\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8838247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import psycopg2\n",
    "\n",
    "# 1. โหลดโมเดล embedding (ใช้ตัวเดิม)\n",
    "embed_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# 2. ฟังก์ชันสืบค้นเอกสารจาก Postgres ตามความใกล้เคียงของเวกเตอร์\n",
    "def retrieve_similar(query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    รับข้อความค้นหา (query) -> แปลงเป็นเวกเตอร์ -> \n",
    "    SELECT เอกสารที่ embedding ใกล้เคียงที่สุด top_k ชิ้น\n",
    "    \"\"\"\n",
    "    # แปลง query เป็นเวกเตอร์\n",
    "    q_vec = embed_model.encode([query], show_progress_bar=False)[0].tolist()\n",
    "\n",
    "    # เชื่อมต่อฐานข้อมูล\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"mydb\", user=\"admin\", password=\"1234\",\n",
    "        host=\"localhost\", port=\"5432\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # ใช้ operator <-> ของ pgvector เพื่อคำนวณระยะ Euclidean\n",
    "    # ต้องแปลง array เป็น vector ด้วย ::vector\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT content, source\n",
    "        FROM documents\n",
    "        ORDER BY embedding <-> (%s::vector)\n",
    "        LIMIT %s\n",
    "    \"\"\", (q_vec, top_k))\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    # คืนผลเป็น list ของ dict\n",
    "    return [{\"content\": r[0], \"source\": r[1]} for r in rows]\n",
    "\n",
    "\n",
    "# 3. ฟังก์ชันรวม context และเรียก LLM (ตัวอย่างสำหรับ local API)\n",
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:5433\"       # แก้เป็น URL ของ LLM service\n",
    "MODEL_NAME = \"scb10x/typhoon2.1-gemma3-4b:latest\"\n",
    "\n",
    "def generate_rag_response(query: str, top_k: int = 5) -> str:\n",
    "    # 3.1 สืบค้นเอกสารที่เกี่ยวข้อง\n",
    "    docs = retrieve_similar(query, top_k)\n",
    "\n",
    "    # 3.2 ประกอบ context\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"Source: {doc['source']}\\n{doc['content']}\" for doc in docs\n",
    "    )\n",
    "    prompt = (\n",
    "        \"คุณคือผู้ช่วยอัจฉริยะ กรุณาตอบคำถามดังนี้\\n\"\n",
    "        f\"---\\nContext:\\n{context}\\n---\\n\"\n",
    "        f\"Question: {query}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # 3.3 เรียก LLM API เพื่อสร้างคำตอบ\n",
    "    res = requests.post(\n",
    "        f\"{API_URL}/api/generate\",\n",
    "        json={\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "คำตอบ:\n",
      "Business look คือวันพฤหัสบดีแรกของเดือน\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. วิธีใช้งาน\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"มีบริการอะไรบ้าง\"\n",
    "    answer = generate_rag_response(question, top_k=2)\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
