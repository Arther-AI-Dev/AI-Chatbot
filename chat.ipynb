{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สวัสดีครับ! ยินดีที่ได้รู้จักครับ ผมชื่อ Typhoon สร้างโดย SCB 10X เพื่อช่วยเหลือคุณอย่างมีประโยชน์ ปลอดภัย และซื่อสัตย์\n",
      "\n",
      "มีอะไรให้ผมช่วยวันนี้ครับ?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:5433\"\n",
    "MODEL_NAME = \"scb10x/typhoon2.1-gemma3-4b:latest\"\n",
    "\n",
    "def generate(prompt: str) -> str:\n",
    "    \"\"\"เรียก /api/generate เพื่อสร้างข้อความตอบกลับ\"\"\"\n",
    "    res = requests.post(\n",
    "        f\"{API_URL}/api/generate\",\n",
    "        json={\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"response\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(generate(\"สวัสดี\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f306588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ได้ทั้งหมด 15 chunks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_and_chunk(directory: str, chunk_size: int = 1600):\n",
    "    \"\"\"อ่านไฟล์ .txt ในโฟลเดอร์ แล้วแบ่งเป็นชิ้นละ chunk_size คำ\"\"\"\n",
    "    chunks = []\n",
    "    for fname in os.listdir(directory):\n",
    "        if not fname.endswith(\".txt\"):\n",
    "            continue\n",
    "        text = open(os.path.join(directory, fname), encoding=\"utf-8\").read()\n",
    "        words = text.split()\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = \" \".join(words[i : i + chunk_size])\n",
    "            # เก็บ metadata เบื้องต้นด้วย\n",
    "            chunks.append({\n",
    "                \"content\": chunk,\n",
    "                \"source\": fname\n",
    "            })\n",
    "    return chunks\n",
    "\n",
    "# usage\n",
    "directory = \"Raw-data-from-TTT\"\n",
    "list_of_chunks = load_and_chunk(directory)\n",
    "print(f\"ได้ทั้งหมด {len(list_of_chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219f718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# โหลดโมเดล embedding\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:11<00:00, 11.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# แปลงเป็นเวกเตอร์\n",
    "texts = [c[\"content\"] for c in list_of_chunks]\n",
    "embeddings = embed_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "# เพิ่ม embedding ลงใน list_of_chunks\n",
    "for chunk, emb in zip(list_of_chunks, embeddings):\n",
    "    chunk[\"vector\"] = emb.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57eff3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mydb\", user=\"admin\", password=\"1234\",\n",
    "    host=\"localhost\", port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "# สร้างตารางถ้ายังไม่มี\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS documents (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        content TEXT,\n",
    "        source TEXT,\n",
    "        embedding VECTOR(1024)\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# แทรกข้อมูล\n",
    "for c in list_of_chunks:\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO documents (content, source, embedding)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", (c[\"content\"], c[\"source\"], c[\"vector\"]))\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8838247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จากข้อมูลที่ให้มา มีวันหยุดที่ตรงกับวันจันทร์ดังนี้:\n",
      "\n",
      "*   วันจันทร์ที่ 7 เมษายน – วันหยุดชดเชยวันจักรี (อาทิตย์ที่ 6 เมษายน 2568)\n",
      "*   วันจันทร์ที่ 12 พฤษภาคม – วันหยุดชดเชยวันวิสาขบูชา (อาทิตย์ที่ 11 พฤษภาคม 2568)\n",
      "*   วันจันทร์ที่ 13 ตุลาคม – วันนวมินทรมหาราช\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n",
    "\n",
    "# โหลดโมเดล embedding\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "# 1. ฟังก์ชันสืบค้นเอกสาร\n",
    "def retrieve_similar(query: str, top_k: int = 7):\n",
    "    \"\"\"\n",
    "    รับข้อความค้นหา (query) -> แปลงเป็นเวกเตอร์ -> \n",
    "    SELECT เอกสารที่ embedding ใกล้เคียงที่สุด top_k ชิ้น\n",
    "    \"\"\"\n",
    "    # แปลง query เป็นเวกเตอร์\n",
    "    q_vec = embed_model.encode([query], show_progress_bar=False)[0].tolist()\n",
    "\n",
    "    # เชื่อมต่อฐานข้อมูล\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"mydb\", user=\"admin\", password=\"1234\",\n",
    "        host=\"localhost\", port=\"5432\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # สืบค้น top_k เอกสาร\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT content, source\n",
    "        FROM documents\n",
    "        ORDER BY embedding <-> (%s::vector)\n",
    "        LIMIT %s\n",
    "    \"\"\", (q_vec, top_k))\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    return [{\"content\": r[0], \"source\": r[1]} for r in rows]\n",
    "\n",
    "\n",
    "API_URL = \"http://localhost:5433\"\n",
    "MODEL_NAME = \"scb10x/typhoon2.1-gemma3-4b:latest\"\n",
    "\n",
    "# 2. ฟังก์ชันเรียก LLM\n",
    "def generate_rag_response(query: str, top_k: int = 7) -> str:\n",
    "    # 2.1 สืบค้นเอกสาร\n",
    "    docs = retrieve_similar(query, top_k)\n",
    "\n",
    "    # 2.2 ประกอบ context\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"Source: {doc['source']}\\n{doc['content']}\" for doc in docs\n",
    "    )\n",
    "    prompt = (\n",
    "        \"คุณคือผู้ช่วยอัจฉริยะชื่อ TTT-Assistant จากบริษัท ทีทีที บราเธอร์ส จำกัด \"\n",
    "        \"กรุณาตอบคำถามให้ละเอียดและครบถ้วนที่สุด โดยใช้ข้อมูลจาก context ที่มี\\n\"\n",
    "        f\"---\\nContext: {context}\\n---\\n\"\n",
    "        f\"Question: {query}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    # 2.3 เรียก LLM API\n",
    "    res = requests.post(\n",
    "        f\"{API_URL}/api/generate\",\n",
    "        json={\"model\": MODEL_NAME, \"prompt\": prompt, \"stream\": False},\n",
    "        timeout=240\n",
    "    )\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"response\"]\n",
    "\n",
    "\n",
    "# 3. วิธีใช้งาน\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"วันหยุดที่ตรงกับวันจันทร์ทั้งหมด\"\n",
    "    answer = generate_rag_response(question)\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
